"""
åŠ¨æ€è®°å¿†å­˜å‚¨æ¨¡å—
æ”¯æŒåŠ¨æ€è®°å¿†ç³»ç»Ÿçš„å­˜å‚¨ã€æ£€ç´¢ã€å¯¼å‡ºç­‰åŠŸèƒ½
ä½¿ç”¨LLMå­¦ä¹ å½¢æˆçš„æ ¼å¼ï¼Œè€Œéžç¡¬ç¼–ç çš„ä¸‰å…ƒç»„æˆ–è¶…å‚æ•°
"""

import json
from typing import Dict, List, Optional
from datetime import datetime
from memory_system import DynamicMemorySystem


class DynamicMemoryStorage:
    """åŠ¨æ€è®°å¿†å­˜å‚¨ç±»"""
    
    def __init__(self, memory_system: DynamicMemorySystem):
        """
        åˆå§‹åŒ–åŠ¨æ€è®°å¿†å­˜å‚¨
        
        Args:
            memory_system: åŠ¨æ€è®°å¿†ç³»ç»Ÿå®žä¾‹
        """
        self.system = memory_system
    
    def export_memories(self, format_type: str = "structured") -> Dict:
        """
        å¯¼å‡ºè®°å¿†ï¼ˆä½¿ç”¨LLMå­¦ä¹ å½¢æˆçš„æ ¼å¼ï¼‰
        
        Args:
            format_type: å¯¼å‡ºæ ¼å¼ç±»åž‹
                - "structured": ç»“æž„åŒ–æ ¼å¼ï¼ˆåŒ…å«æ‰€æœ‰å…ƒæ•°æ®ï¼‰
                - "semantic": è¯­ä¹‰åŒ–æ ¼å¼ï¼ˆä¾¿äºŽç†è§£ï¼‰
                - "minimal": æœ€å°æ ¼å¼ï¼ˆä»…æ ¸å¿ƒä¿¡æ¯ï¼‰
                
        Returns:
            å¯¼å‡ºçš„è®°å¿†æ•°æ®
        """
        if format_type == "structured":
            return self._export_structured()
        elif format_type == "semantic":
            return self._export_semantic()
        elif format_type == "minimal":
            return self._export_minimal()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼ç±»åž‹: {format_type}")
    
    def _export_structured(self) -> Dict:
        """å¯¼å‡ºç»“æž„åŒ–æ ¼å¼ï¼ˆåŒ…å«å®Œæ•´å…ƒæ•°æ®ï¼‰"""
        return {
            "memories": self.system.memories,
            "access_history": self.system.access_history,
            "importance_scores": self.system.importance_scores,
            "statistics": self.system.get_statistics(),
            "export_timestamp": datetime.now().isoformat()
        }
    
    def _export_semantic(self) -> Dict:
        """å¯¼å‡ºè¯­ä¹‰åŒ–æ ¼å¼ï¼ˆä¾¿äºŽäººç±»ç†è§£ï¼‰"""
        semantic_data = {
            "episodic_memories": [],
            "semantic_memories": [],
            "procedural_memories": [],
            "export_timestamp": datetime.now().isoformat()
        }
        
        for memory in self.system.memories:
            mem_type = memory.get("type", "unknown")
            importance = self.system.importance_scores.get(memory["id"], 0.5)
            
            mem_entry = {
                "id": memory["id"],
                "content": memory.get("content", ""),
                "importance": importance,
                "confidence": memory.get("confidence", 0.5),
                "extracted_info": memory.get("extracted_info", {}),
                "created_at": memory.get("created_at"),
                "updated_at": memory.get("updated_at"),
                "access_count": memory.get("access_count", 0)
            }
            
            if mem_type == "episodic":
                semantic_data["episodic_memories"].append(mem_entry)
            elif mem_type == "semantic":
                semantic_data["semantic_memories"].append(mem_entry)
            elif mem_type == "procedural":
                semantic_data["procedural_memories"].append(mem_entry)
        
        return semantic_data
    
    def _export_minimal(self) -> Dict:
        """å¯¼å‡ºæœ€å°æ ¼å¼ï¼ˆä»…æ ¸å¿ƒä¿¡æ¯ï¼‰"""
        minimal_data = {
            "memories": [],
            "statistics": self.system.get_statistics()
        }
        
        for memory in self.system.memories:
            minimal_data["memories"].append({
                "id": memory["id"],
                "type": memory.get("type"),
                "content": memory.get("content", ""),
                "importance": self.system.importance_scores.get(memory["id"], 0.5)
            })
        
        return minimal_data
    
    def generate_storage_output(self, output_format: str = "semantic") -> Dict:
        """
        ç”Ÿæˆå­˜å‚¨æ ¼å¼è¾“å‡ºï¼ˆå‘åŽå…¼å®¹æŽ¥å£ï¼‰
        
        Args:
            output_format: è¾“å‡ºæ ¼å¼
            
        Returns:
            å­˜å‚¨è¾“å‡ºæ•°æ®
        """
        return self.export_memories(format_type=output_format)
    
    def save_storage_output(self, output_file: str = "memory/dynamic_memory_output.json", format_type: str = "semantic"):
        """
        ä¿å­˜å­˜å‚¨æ ¼å¼çš„è¾“å‡º
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶å
            format_type: æ ¼å¼ç±»åž‹
        """
        output = self.export_memories(format_type=format_type)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        stats = self.system.get_statistics()
        print(f"\nâœ… åŠ¨æ€è®°å¿†è¾“å‡ºå·²ä¿å­˜åˆ°: {output_file}")
        print(f"ðŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»è®°å¿†æ•°: {stats['total']}")
        if 'by_type' in stats:
            for mem_type, count in stats['by_type'].items():
                type_names = {
                    "episodic": "æƒ…æ™¯è®°å¿†",
                    "semantic": "è¯­ä¹‰è®°å¿†",
                    "procedural": "ç¨‹åºè®°å¿†"
                }
                print(f"   {type_names.get(mem_type, mem_type)}: {count} æ¡")
        print(f"   å¹³å‡é‡è¦æ€§: {stats.get('average_importance', 0):.2f}")
        print(f"   æ€»è®¿é—®æ¬¡æ•°: {stats.get('total_access_count', 0)}")
        
        return output
    
    def analyze_memory_patterns(self) -> Dict:
        """
        åˆ†æžè®°å¿†æ¨¡å¼ï¼ˆä½¿ç”¨ç»Ÿè®¡æ–¹æ³•ï¼Œè€Œéžç¡¬ç¼–ç è§„åˆ™ï¼‰
        
        Returns:
            è®°å¿†æ¨¡å¼åˆ†æžç»“æžœ
        """
        patterns = {
            "temporal_patterns": {},
            "semantic_clusters": {},
            "importance_distribution": {},
            "access_patterns": {}
        }
        
        # åˆ†æžæ—¶é—´æ¨¡å¼
        for memory in self.system.memories:
            created_at = memory.get("created_at", "")
            if created_at:
                try:
                    dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                    hour = dt.hour
                    patterns["temporal_patterns"][hour] = patterns["temporal_patterns"].get(hour, 0) + 1
                except:
                    pass
        
        # é‡è¦æ€§åˆ†å¸ƒ
        importance_values = list(self.system.importance_scores.values())
        if importance_values:
            patterns["importance_distribution"] = {
                "mean": sum(importance_values) / len(importance_values),
                "min": min(importance_values),
                "max": max(importance_values),
                "high_importance_count": sum(1 for v in importance_values if v > 0.7),
                "low_importance_count": sum(1 for v in importance_values if v < 0.3)
            }
        
        # è®¿é—®æ¨¡å¼
        total_access = sum(m.get("access_count", 0) for m in self.system.memories)
        patterns["access_patterns"] = {
            "total_access": total_access,
            "average_access_per_memory": total_access / len(self.system.memories) if self.system.memories else 0,
            "most_accessed": sorted(
                [(m["id"], m.get("access_count", 0)) for m in self.system.memories],
                key=lambda x: x[1],
                reverse=True
            )[:5]
        }
        
        return patterns


if __name__ == "__main__":
    from llm_interface import create_llm
    from memory_system import DynamicMemorySystem
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    llm = create_llm("mock")
    system = DynamicMemorySystem(llm)
    
    # åˆ›å»ºå­˜å‚¨å¯¹è±¡
    storage = DynamicMemoryStorage(system)
    
    # æµ‹è¯•ï¼šå­˜å‚¨ä¸€äº›è®°å¿†
    system.store("2023å¹´5æœˆ15æ—¥ä¸‹åˆ3ç‚¹ï¼Œæˆ‘åœ¨æ˜Ÿå·´å…‹å’–å•¡åº—é‡åˆ°äº†å¤§å­¦åŒå­¦æŽæ˜Žã€‚")
    system.store("Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”±Guido van Rossumåˆ›å»ºã€‚")
    
    # ç”Ÿæˆå¹¶ä¿å­˜å­˜å‚¨æ ¼å¼è¾“å‡º
    storage.save_storage_output(format_type="semantic")
    
    # åˆ†æžè®°å¿†æ¨¡å¼
    patterns = storage.analyze_memory_patterns()
    print("\nè®°å¿†æ¨¡å¼åˆ†æž:")
    print(json.dumps(patterns, ensure_ascii=False, indent=2))
